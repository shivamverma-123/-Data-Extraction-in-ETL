{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FN9TmHK59-s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Extraction in ETL\n",
        "\n",
        "Question 1 : Describe different types of data sources used in ETL with suitable examples.\n",
        "\n",
        "Ans:In ETL, data can come from multiple sources:\n",
        "\n",
        "1.Relational Databases\n",
        "\n",
        "- Structured data stored in tables\n",
        "\n",
        "- Examples: MySQL, PostgreSQL, Oracle, SQL Server\n",
        "\n",
        "- Example: Customer and sales data from a MySQL database\n",
        "\n",
        "2.Flat Files\n",
        "\n",
        "- Data stored in files\n",
        "\n",
        "- Examples: CSV, TXT, Excel\n",
        "\n",
        "- Example: Daily sales report in sales.csv\n",
        "\n",
        "3.APIs (Web Services)\n",
        "\n",
        "- Data accessed via HTTP requests\n",
        "\n",
        "- Examples: REST APIs, SOAP APIs\n",
        "\n",
        "- Example: Weather data from an API, payment data from Razorpay API\n",
        "\n",
        "4.Cloud Storage\n",
        "\n",
        "- Data stored in cloud platforms\n",
        "\n",
        "- Examples: AWS S3, Google Cloud Storage, Azure Blob\n",
        "\n",
        "- Example: Log files stored in AWS S3\n",
        "\n",
        "5.Streaming Sources\n",
        "\n",
        "- Real-time data\n",
        "\n",
        "- Examples: Kafka, Kinesis\n",
        "\n",
        "- Example: Live user activity data from a website\n",
        "\n",
        "\n",
        "Question 2 : What is data extraction? Explain its role in the ETL pipeline.\n",
        "\n",
        "Ans:Data extraction is the process of collecting data from various source systems for further processing.\n",
        "\n",
        "Role in ETL:\n",
        "\n",
        "- It is the first step of ETL\n",
        "\n",
        "- Ensures accurate and complete data is collected\n",
        "\n",
        "- Extracted data is later cleaned, transformed, and loaded into a data warehouse\n",
        "\n",
        "Example:\n",
        "Extracting sales data from a MySQL database before transforming it for analytics.\n",
        "\n",
        "Question 3 : Explain the difference between CSV and Excel in terms of extraction and ETL usage.\n",
        "\n",
        "Ans:The difference between csv and excel in terms of extraction and etl usages are\n",
        "\n",
        "| Feature          | CSV                    | Excel                     |\n",
        "| ---------------- | ---------------------- | ------------------------- |\n",
        "| Format           | Plain text             | Binary                    |\n",
        "| Structure        | Simple rows & columns  | Multiple sheets, formulas |\n",
        "| Size Handling    | Better for large files | Slower for large files    |\n",
        "| ETL Usage        | Preferred              | Less preferred            |\n",
        "| Processing Speed | Fast                   | Slow                      |\n",
        "\n",
        "\n",
        "Question 4 : Explain the steps involved in extracting data from a relational database.\n",
        "\n",
        "Ans:the steps involved in extracting data from a relational database.\n",
        "\n",
        "1.Identify source database and tables\n",
        "\n",
        "2.Establish database connection (using credentials)\n",
        "\n",
        "3.Write SQL queries (SELECT)\n",
        "\n",
        "4.Apply filters (WHERE, JOIN, LIMIT)\n",
        "\n",
        "5.Extract data in batches or full load\n",
        "\n",
        "6.Store extracted data temporarily (CSV, staging table).\n",
        "\n",
        "Question 5 : Explain three common challenges faced during data extraction.\n",
        "\n",
        "Ans:three common challenges faced during data extraction are\n",
        "\n",
        "1.Data Quality Issues\n",
        "\n",
        "  - Missing values, duplicates, inconsistent formats\n",
        "\n",
        "2.Performance Issues\n",
        "\n",
        "  - Slow extraction from large databases\n",
        "\n",
        "3.Schema Changes\n",
        "\n",
        "  - Column name/type changes break ETL jobs.\n",
        "\n",
        "Question 6 : What are APIs? Explain how APIs help in real-time data extraction.\n",
        "\n",
        "Ans:APIs (Application Programming Interfaces) allow applications to communicate with each other.\n",
        "\n",
        "How APIs help in real-time extraction:\n",
        "\n",
        "- Provide live data access\n",
        "\n",
        "- Support JSON/XML responses\n",
        "\n",
        "- Enable automated and continuous data fetching\n",
        "\n",
        "Example:\n",
        "Fetching live stock prices using a REST API.\n",
        "\n",
        "Question 7 : Why are databases preferred for enterprise-level data extraction?\n",
        "\n",
        "Ans:Databases are preferred because:\n",
        "\n",
        "- Handle large volumes of data efficiently\n",
        "\n",
        "- Support transactions and consistency\n",
        "\n",
        "- Allow incremental extraction\n",
        "\n",
        "- Provide security and access control\n",
        "\n",
        "- Support complex queries.\n",
        "\n",
        "Question 8 : What steps should an ETL developer take when extracting data from large CSV files (1GB+)?\n",
        "\n",
        "Ans:steps should an ETL developer take when extracting data from large CSV files (1GB+) are\n",
        "\n",
        "1.Read data in chunks\n",
        "\n",
        "2.Avoid loading full file into memory\n",
        "\n",
        "3.Use efficient tools (Pandas chunking, Spark)\n",
        "\n",
        "4.Validate schema before processing\n",
        "\n",
        "5.Compress files if possible\n",
        "\n",
        "6.Log extraction progress\n",
        "\n",
        "7.Perform parallel processing if supported\n",
        "\n"
      ],
      "metadata": {
        "id": "_wFbh7p-6Emh"
      }
    }
  ]
}